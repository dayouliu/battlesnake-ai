{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook was used to conduct the experiments presented in the paper \"Battlesnake Challenge: A Multi-agent Reinforcement Learning Playground with Human-in-the-loop\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.rl import RLEstimator, RLToolkit\n",
    "import boto3\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../stack_outputs.json\") as f:\n",
    "    info = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialise sagemaker\n",
    "We need to define several parameters prior to running the training job. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_session = sagemaker.session.Session()\n",
    "s3_bucket = info[\"S3Bucket\"]\n",
    "\n",
    "s3_output_path = 's3://{}/'.format(s3_bucket)\n",
    "print(\"S3 bucket path: {}\".format(s3_output_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = sagemaker.get_execution_role()\n",
    "print(role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_mode = False\n",
    "\n",
    "if local_mode:\n",
    "    instance_type = 'local'\n",
    "else:\n",
    "    instance_type = info[\"SagemakerTrainingInstanceType\"]\n",
    "    \n",
    "# If training locally, do some Docker housekeeping..\n",
    "if local_mode:\n",
    "    !/bin/bash ./common/setup.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = sm_session.boto_region_name\n",
    "device = \"cpu\"\n",
    "image_name = '462105765813.dkr.ecr.{region}.amazonaws.com/sagemaker-rl-ray-container:ray-0.8.2-tf-{device}-py36'.format(region=region, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "configs = {\"PPO\": {\n",
    "                \"algorithm\": \"PPO\",\n",
    "                \"additional_config\": {\n",
    "                    'lambda': 0.90,\n",
    "                    'gamma': 0.999,\n",
    "                    'kl_coeff': 0.2,\n",
    "                    'clip_rewards': True,\n",
    "                    'vf_clip_param': 175.0,\n",
    "                    'train_batch_size': 9216,\n",
    "                    'sample_batch_size': 96,\n",
    "                    'sgd_minibatch_size': 256,\n",
    "                    'num_sgd_iter': 3,\n",
    "                    'lr': 5.0e-4,\n",
    "                }\n",
    "            }\n",
    "          }\n",
    "\n",
    "iterations = 3000\n",
    "vanilla_rewards = {\"another_turn\": 0.01,\n",
    "                    \"ate_food\": 0,\n",
    "                    \"won\": 5,\n",
    "                    \"died\": -5,\n",
    "                    \"ate_another_snake\": 0,\n",
    "                    \"hit_wall\": 0,\n",
    "                    \"hit_other_snake\": 0,\n",
    "                    \"hit_self\": 0,\n",
    "                    \"was_eaten\": 0,\n",
    "                    \"other_snake_hit_body\": 0,\n",
    "                    \"forbidden_move\": 0,\n",
    "                    \"starved\": 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_definitions =  [\n",
    "    {'Name': 'training_iteration', 'Regex': 'training_iteration: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'}, \n",
    "    {'Name': 'episodes_total', 'Regex': 'episodes_total: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'}, \n",
    "    {'Name': 'num_steps_trained', 'Regex': 'num_steps_trained: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'}, \n",
    "    {'Name': 'timesteps_total', 'Regex': 'timesteps_total: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'},\n",
    "    {'Name': 'training_iteration', 'Regex': 'training_iteration: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'},\n",
    "\n",
    "    {'Name': 'episode_reward_max', 'Regex': 'episode_reward_max: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'}, \n",
    "    {'Name': 'episode_reward_mean', 'Regex': 'episode_reward_mean: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'}, \n",
    "    {'Name': 'episode_reward_min', 'Regex': 'episode_reward_min: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'}, \n",
    "    \n",
    "    {'Name': 'episode_len_max', 'Regex': 'episode_len_max: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'}, \n",
    "    {'Name': 'episode_len_mean', 'Regex': 'episode_len_mean: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'}, \n",
    "    {'Name': 'episode_len_min', 'Regex': 'episode_len_min: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'}, \n",
    "\n",
    "    {'Name': 'best_snake_episode_len_max', 'Regex': 'best_snake_episode_len_max: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'},\n",
    "    {'Name': 'worst_snake_episode_len_max', 'Regex': 'worst_snake_episode_len_max: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'},\n",
    "\n",
    "    {'Name': 'Snake_hit_wall_max', 'Regex': 'Snake_hit_wall_max: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'},\n",
    "    {'Name': 'Snake_was_eaten_max', 'Regex': 'Snake_was_eaten_max: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'},\n",
    "    {'Name': 'Killed_another_snake_max', 'Regex': 'Killed_another_snake_max: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'},\n",
    "    {'Name': 'Snake_hit_body_max', 'Regex': 'Snake_hit_body_max: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'},\n",
    "    {'Name': 'Starved_max', 'Regex': 'Starved_max: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'},\n",
    "    {'Name': 'Forbidden_move_max', 'Regex': 'Forbidden_move_max: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'}\n",
    "] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla\n",
    "Train the policy without any HILL varying between the number of agents and map size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_conditions = [(3, 11), (5, 11), (5, 7), (5, 19), (7, 11)]\n",
    "\n",
    "job_name_prefix_base = 'Battlesnake-no-hill-'\n",
    "\n",
    "for num_agents, map_size in test_conditions:\n",
    "    for name in configs:\n",
    "        algorithm = configs[name][\"algorithm\"]\n",
    "        additional_config = configs[name][\"additional_config\"]\n",
    "        job_name_prefix = job_name_prefix_base + \"{}-s{}m{}\".format(name, num_agents, map_size)\n",
    "        print(\"job_prefix {}\".format(job_name_prefix))\n",
    "\n",
    "        estimator = RLEstimator(entry_point=\"train-mabs.py\",\n",
    "                                source_dir='training/training_src',\n",
    "                                dependencies=[\"training/common/sagemaker_rl\", \"inference/inference_src/\", \"../BattlesnakeGym/\"],\n",
    "                                image_name=image_name,\n",
    "                                role=role,\n",
    "                                train_instance_type=instance_type,\n",
    "                                train_instance_count=1,\n",
    "                                output_path=s3_output_path,\n",
    "                                base_job_name=job_name_prefix,\n",
    "                                metric_definitions=metric_definitions,\n",
    "                                hyperparameters={\n",
    "                                    # See train-mabs.py to add additional hyperparameters\n",
    "                                    # Also see ray_launcher.py for the rl.training.* hyperparameters\n",
    "                                    #\n",
    "                                    # number of training iterations\n",
    "                                    \"num_iters\": iterations,\n",
    "                                    # number of snakes in the gym\n",
    "                                    \"num_agents\": num_agents,\n",
    "\n",
    "                                    \"iterate_map_size\": False,\n",
    "                                    \"use_heuristics_action_masks\": False,\n",
    "                                    \"map_size\": map_size,\n",
    "                                    \"algorithm\": algorithm,\n",
    "                                    \"additional_configs\": additional_config,\n",
    "                                    \"rewards\": vanilla_rewards\n",
    "                                }\n",
    "                            )\n",
    "\n",
    "        estimator.fit(wait=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HILL: in-training action masking\n",
    "Train the policies with in-training action masking with 5 agents and a 11x11 map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_conditions = [(5, 11)]\n",
    "heuristics = [\"banned_wall_hits\", \"banned_forbidden_moves\"]\n",
    "job_name_prefix_base = 'Battlesnake-in-training-am-'\n",
    "\n",
    "for num_agents, map_size in test_conditions:\n",
    "    for heuristic in heuristics:\n",
    "        for name in configs:\n",
    "            algorithm = configs[name][\"algorithm\"]\n",
    "            additional_config = configs[name][\"additional_config\"]\n",
    "            job_name_prefix = job_name_prefix_base + \"{}-{}-\".format(name, heuristic.replace(\"_\", \"-\")[7:])\n",
    "            print(\"job_prefix {}\".format(job_name_prefix))\n",
    "\n",
    "            estimator = RLEstimator(entry_point=\"train-mabs.py\",\n",
    "                                    source_dir='training/training_src',\n",
    "                                    dependencies=[\"training/common/sagemaker_rl\", \"inference/inference_src/\", \"../BattlesnakeGym/\"],\n",
    "                                    image_name=image_name,\n",
    "                                    role=role,\n",
    "                                    train_instance_type=instance_type,\n",
    "                                    train_instance_count=1,\n",
    "                                    output_path=s3_output_path,\n",
    "                                    base_job_name=job_name_prefix,\n",
    "                                    metric_definitions=metric_definitions,\n",
    "                                    hyperparameters={\n",
    "                                        # See train-mabs.py to add additional hyperparameters\n",
    "                                        # Also see ray_launcher.py for the rl.training.* hyperparameters\n",
    "                                        #\n",
    "                                        # number of training iterations\n",
    "                                        \"num_iters\": iterations,\n",
    "                                        # number of snakes in the gym\n",
    "                                        \"num_agents\": num_agents,\n",
    "\n",
    "                                        \"iterate_map_size\": False,\n",
    "                                        \"heuristics\": [heuristic],\n",
    "                                        \"map_size\": map_size,\n",
    "                                        \"algorithm\": algorithm,\n",
    "                                        \"additional_configs\": additional_config,\n",
    "                                        \"rewards\": vanilla_rewards\n",
    "                                    }\n",
    "                                )\n",
    "\n",
    "        estimator.fit(wait=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HILL: reward manipulation\n",
    "Train the policy with reward manipulation with 5 agents and a 11x11 map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forbidden_move_rewards = {\"another_turn\": 0.01,\n",
    "                            \"ate_food\": 0,\n",
    "                            \"won\": 5,\n",
    "                            \"died\": -5,\n",
    "                            \"ate_another_snake\": 0,\n",
    "                            \"hit_wall\": 0,\n",
    "                            \"hit_other_snake\": 0,\n",
    "                            \"hit_self\": 0,\n",
    "                            \"was_eaten\": 0,\n",
    "                            \"other_snake_hit_body\": 0,\n",
    "                            \"forbidden_move\": -2,\n",
    "                            \"starved\": 0}\n",
    "\n",
    "hit_wall_rewards = {\"another_turn\": 0.01,\n",
    "                    \"ate_food\": 0,\n",
    "                    \"won\": 5,\n",
    "                    \"died\": -5,\n",
    "                    \"ate_another_snake\": 0,\n",
    "                    \"hit_wall\": -2,\n",
    "                    \"hit_other_snake\": 0,\n",
    "                    \"hit_self\": 0,\n",
    "                    \"was_eaten\": 0,\n",
    "                    \"other_snake_hit_body\": 0,\n",
    "                    \"forbidden_move\": 0,\n",
    "                    \"starved\": 0}\n",
    "\n",
    "starved_rewards = {\"another_turn\": 0.01,\n",
    "                    \"ate_food\": 0,\n",
    "                    \"won\": 5,\n",
    "                    \"died\": 5,\n",
    "                    \"ate_another_snake\": 0,\n",
    "                    \"hit_wall\": 0,\n",
    "                    \"hit_other_snake\": 0,\n",
    "                    \"hit_self\": 0,\n",
    "                    \"was_eaten\": 0,\n",
    "                    \"other_snake_hit_body\": 0,\n",
    "                    \"forbidden_move\": 0,\n",
    "                    \"starved\": -2}\n",
    "\n",
    "kill_other_snake_rewards = {\"another_turn\": 0.01,\n",
    "                            \"ate_food\": 0,\n",
    "                            \"won\": 5,\n",
    "                            \"died\": -5,\n",
    "                            \"ate_another_snake\": 2,\n",
    "                            \"hit_wall\": 0,\n",
    "                            \"hit_other_snake\": 0,\n",
    "                            \"hit_self\": 0,\n",
    "                            \"was_eaten\": 0,\n",
    "                            \"other_snake_hit_body\": 2,\n",
    "                            \"forbidden_move\": 0,\n",
    "                            \"starved\": 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_conditions = [(5, 11)]\n",
    "rewards_dicts = [(\"for-move-\", forbidden_move_rewards), (\"hit-wall\", hit_wall_rewards), \n",
    "                 (\"starved\", starved_rewards), (\"kill\", kill_other_snake_rewards)]\n",
    "\n",
    "job_name_prefix_base = 'Battlesnake-reward-manipulation-'\n",
    "\n",
    "for reward_name, reward_dict in rewards_dicts:\n",
    "    for num_agents, map_size in test_conditions:\n",
    "        for name in configs:\n",
    "            algorithm = configs[name][\"algorithm\"]\n",
    "            additional_config = configs[name][\"additional_config\"]\n",
    "            job_name_prefix = job_name_prefix_base + \"{}-{}-\".format(name, reward_name)\n",
    "            print(\"job_prefix {}\".format(job_name_prefix))\n",
    "\n",
    "            estimator = RLEstimator(entry_point=\"train-mabs.py\",\n",
    "                                    source_dir='training/training_src',\n",
    "                                    dependencies=[\"training/common/sagemaker_rl\", \"inference/inference_src/\", \"../BattlesnakeGym/\"],\n",
    "                                    image_name=image_name,\n",
    "                                    role=role,\n",
    "                                    train_instance_type=instance_type,\n",
    "                                    train_instance_count=1,\n",
    "                                    output_path=s3_output_path,\n",
    "                                    base_job_name=job_name_prefix,\n",
    "                                    metric_definitions=metric_definitions,\n",
    "                                    hyperparameters={\n",
    "                                        # See train-mabs.py to add additional hyperparameters\n",
    "                                        # Also see ray_launcher.py for the rl.training.* hyperparameters\n",
    "                                        #\n",
    "                                        # number of training iterations\n",
    "                                        \"num_iters\": iterations,\n",
    "                                        # number of snakes in the gym\n",
    "                                        \"num_agents\": num_agents,\n",
    "\n",
    "                                        \"iterate_map_size\": False,\n",
    "                                        \"use_heuristics_action_masks\": False,\n",
    "                                        \"map_size\": map_size,\n",
    "                                        \"algorithm\": algorithm,\n",
    "                                        \"additional_configs\": additional_config,\n",
    "                                        \"rewards\": reward_dict\n",
    "                                    }\n",
    "                                )\n",
    "\n",
    "            estimator.fit(wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow JumpStart)",
   "language": "python",
   "name": "HUB_1P_IMAGE"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
